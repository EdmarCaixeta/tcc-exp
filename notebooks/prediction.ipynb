{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import os\n",
    "from torchvision.models import alexnet\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Tuple, List\n",
    "from PIL import Image\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_CHECKPOINT = \"/home/kenzo/experiments/alexnet-pretrained-super_aug-200ep/fold9/MyAlexNetPretrained_200.pth\"\n",
    "PATH_TO_IMAGES = \"/home/kenzo/datasets/embrapa/Fake-P2-dataset\"\n",
    "PATH_TO_LABELS = \"/hd4t/home/biomassa/exp/GSD05/2019-01-23/labels/annotation.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:2\""
   ]
  },
  {
   "source": [
    "# Carregando modelo pre-treinado"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUDO ISSO PARA CARREGAR UMA ALEXNET DISGRAÇAAA\n",
    "\n",
    "class BaseConvNet(nn.Module):\n",
    "    def __init__(self, name: str = \"Model\",\n",
    "                       features: nn.Sequential = None, \n",
    "                       classifier: nn.Sequential = None):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self._features = features\n",
    "        self._classifier = classifier\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self._features(x)\n",
    "        print(x.shape)\n",
    "        x = self._classifier(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class AlexNet(BaseConvNet):\n",
    "    def __init__(self, nClasses):\n",
    "        features = nn.Sequential(\n",
    "            # first layer\n",
    "            nn.Conv2d(3, 96, 11, stride=4),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            # second layer\n",
    "            nn.Conv2d(96, 256, 5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            # third layer\n",
    "            nn.Conv2d(256, 384, 3, padding=1),\n",
    "            nn.ReLU(inplace=False),\n",
    "            # fourth layer\n",
    "            nn.Conv2d(384, 384, 3, padding=1),\n",
    "            nn.ReLU(inplace=False),\n",
    "            # fifth layer\n",
    "            nn.Conv2d(384, 256, 3, padding=1),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.MaxPool2d(3, stride=2))\n",
    "        \n",
    "        classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(6*6*256, 4096, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 4096, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, nClasses, bias=True)\n",
    "        )\n",
    "\n",
    "        super().__init__(\"AlexNet\", features, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imagent_alexNet():\n",
    "    net = alexnet(pretrained=True)\n",
    "    \n",
    "    regressor = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(10*6*256, 4096, bias=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(4096, 4096, bias=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(4096, 1, bias=True))\n",
    "    net.classifier = regressor\n",
    "\n",
    "    net.name = \"ImagenetAlexNet\"\n",
    "    return net\n",
    "\n",
    "def get_alexNet():\n",
    "    net = AlexNet(1)\n",
    "    \n",
    "    regressor = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(10*6*256, 4096, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 4096, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 1, bias=True))\n",
    "    \n",
    "    net._classifier = regressor\n",
    "\n",
    "    return net\n",
    "\n",
    "def get_myalexnet_pretrained():\n",
    "    net = get_alexNet()\n",
    "    imagenet_alexnet = get_imagent_alexNet()\n",
    "    net._features = imagenet_alexnet.features\n",
    "    net.name = \"MyAlexNetPretrained\"\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_myalexnet_pretrained() # mas que monstruosidade é essa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(PATH_TO_CHECKPOINT, map_location=device)[\"state_dict\"], strict=False)"
   ]
  },
  {
   "source": [
    "# Preparando um dataset para inferência"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(xstats: dict):\n",
    "\n",
    "    normalize = transforms.Normalize(mean=xstats[\"mean\"], std=xstats[\"std\"])\n",
    "\n",
    "    t = transforms.Compose([\n",
    "            transforms.Resize(227),\n",
    "            transforms.ToTensor(),\n",
    "            normalize])\n",
    "            \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 source_dir: str,\n",
    "                 transforms: transforms.Compose):\n",
    "\n",
    "        self.images = [os.path.join(source_dir, image) for image in os.listdir(source_dir)]\n",
    "        self.transform = transforms\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, i) -> torch.Tensor:\n",
    "\n",
    "        image_path = self.images[i]\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        return self.transform(image)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = json.load(open(PATH_TO_LABELS, \"r\"))\n",
    "xstats = annotations[\"statistics\"][\"x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = get_transforms(xstats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = InferenceDataset(PATH_TO_IMAGES, transforms)\n",
    "dl = DataLoader(ds, batch_size=32, shuffle=False)"
   ]
  },
  {
   "source": [
    "# Aplicando predição em imagens novas"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, inference_dl, device = \"cpu\"):\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for image_batch in inference_dl:\n",
    "\n",
    "            image_batch = image_batch.to(device)\n",
    "            preds = model(image_batch).view(-1)\n",
    "            predictions.extend(preds.tolist())\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([32, 256, 10, 6])\ntorch.Size([1, 256, 10, 6])\n"
     ]
    }
   ],
   "source": [
    "preds = predict(model.to(device), dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame()\n",
    "# preds_df[\"images\"] = ds.images\n",
    "preds_df[\"Predicao\"] = preds\n",
    "preds_df[\"Parcela\"] = [int(name[59:62]) for name in ds.images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Predicao  Parcela\n",
       "0    6209.011719      223\n",
       "1    5034.480957      164\n",
       "2    6704.708008      203\n",
       "3   10354.244141       21\n",
       "4   11809.332031      166\n",
       "5    9114.894531      329\n",
       "6    7003.057129       69\n",
       "7    5908.583984      304\n",
       "8   14603.240234      277\n",
       "9   10123.066406       60\n",
       "10  13485.550781       54\n",
       "11   4851.224121      317\n",
       "12  10125.841797       89\n",
       "13   7234.212891       57\n",
       "14   4517.504883      239\n",
       "15   3838.979248      230\n",
       "16   8298.465820       68\n",
       "17   5653.520996      250\n",
       "18   5924.874512      232\n",
       "19  11777.715820       35\n",
       "20   9212.570312       11\n",
       "21   8329.528320       95\n",
       "22  11273.249023       90\n",
       "23   4994.567871      179\n",
       "24   4537.287598      142\n",
       "25  10893.358398      274\n",
       "26   5117.642090      191\n",
       "27   5278.844238      237\n",
       "28   8661.010742        5\n",
       "29   4452.889648       93\n",
       "30  12973.762695      257\n",
       "31   9522.789062      311\n",
       "32   4708.687012      145"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Predicao</th>\n      <th>Parcela</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6209.011719</td>\n      <td>223</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5034.480957</td>\n      <td>164</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6704.708008</td>\n      <td>203</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10354.244141</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11809.332031</td>\n      <td>166</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>9114.894531</td>\n      <td>329</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7003.057129</td>\n      <td>69</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>5908.583984</td>\n      <td>304</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>14603.240234</td>\n      <td>277</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10123.066406</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>13485.550781</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>4851.224121</td>\n      <td>317</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>10125.841797</td>\n      <td>89</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>7234.212891</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>4517.504883</td>\n      <td>239</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>3838.979248</td>\n      <td>230</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>8298.465820</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>5653.520996</td>\n      <td>250</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>5924.874512</td>\n      <td>232</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>11777.715820</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>9212.570312</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>8329.528320</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>11273.249023</td>\n      <td>90</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>4994.567871</td>\n      <td>179</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>4537.287598</td>\n      <td>142</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>10893.358398</td>\n      <td>274</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>5117.642090</td>\n      <td>191</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>5278.844238</td>\n      <td>237</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>8661.010742</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>4452.889648</td>\n      <td>93</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>12973.762695</td>\n      <td>257</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>9522.789062</td>\n      <td>311</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>4708.687012</td>\n      <td>145</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}